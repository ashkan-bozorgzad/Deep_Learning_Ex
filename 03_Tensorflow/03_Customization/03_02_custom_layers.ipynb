{"cells":[{"cell_type":"markdown","metadata":{"id":"60RdWsg1tETW"},"source":["# Custom layers"]},{"cell_type":"markdown","metadata":{"id":"UEu3q4jmpKVT"},"source":["We recommend using `tf.keras` as a high-level API for building neural networks. That said, most TensorFlow APIs are usable with eager execution.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Py0m-N6VgQFJ","executionInfo":{"status":"ok","timestamp":1705887028001,"user_tz":480,"elapsed":206,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TluWFcB_2nP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705887028847,"user_tz":480,"elapsed":6,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"84a783dc-7332-4156-dc10-9063744c8929"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"source":["print(tf.config.list_physical_devices('GPU'))"]},{"cell_type":"markdown","metadata":{"id":"zSFfVVjkrrsI"},"source":["## Layers: common sets of useful operations\n","\n","Most of the time when writing code for machine learning models you want to operate at a higher level of abstraction than individual operations and manipulation of individual variables.\n","\n","Many machine learning models are expressible as the composition and stacking of relatively simple layers, and TensorFlow provides both a set of many common layers as well as easy ways for you to write your own application-specific layers either from scratch or as the composition of existing layers.\n","\n","TensorFlow includes the full [Keras](https://keras.io) API in the tf.keras package, and the Keras layers are very useful when building your own models.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8PyXlPl-4TzQ","executionInfo":{"status":"ok","timestamp":1705887625424,"user_tz":480,"elapsed":152,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}}},"outputs":[],"source":["# In the tf.keras.layers package, layers are objects. To construct a layer,\n","# simply construct the object. Most layers take as a first argument the number\n","# of output dimensions / channels.\n","layer = tf.keras.layers.Dense(100)\n","# The number of input dimensions is often unnecessary, as it can be inferred\n","# the first time the layer is used, but it can be provided if you want to\n","# specify it manually, which is useful in some complex models.\n","layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"]},{"cell_type":"markdown","metadata":{"id":"Fn69xxPO5Psr"},"source":["The full list of pre-existing layers can be seen in [the documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers). It includes Dense (a fully-connected layer),\n","Conv2D, LSTM, BatchNormalization, Dropout, and many others."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"E3XKNknP5Mhb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705887632610,"user_tz":480,"elapsed":142,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"097bb706-ea14-4a84-870c-6e59479161a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n","array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"]},"metadata":{},"execution_count":13}],"source":["# To use a layer, simply call it.\n","layer(tf.zeros([10, 5]))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Wt_Nsv-L5t2s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705887635081,"user_tz":480,"elapsed":141,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"12f3bf4a-8254-4917-d1ed-3ae59987ecc3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'dense_7/kernel:0' shape=(5, 10) dtype=float32, numpy=\n"," array([[ 0.41905028, -0.14225042, -0.54180515, -0.15413108,  0.56353897,\n","          0.00223833, -0.09507346, -0.296003  , -0.01942104, -0.34390724],\n","        [ 0.5273344 ,  0.34390193, -0.28642127, -0.5911583 , -0.16138011,\n","          0.22381091, -0.31642318,  0.03402799, -0.37771913, -0.3501223 ],\n","        [-0.43251273,  0.45806664,  0.38762993, -0.18399638,  0.13132632,\n","          0.41890818,  0.57048696,  0.14705741, -0.3811912 ,  0.37444776],\n","        [-0.09519547,  0.17809075,  0.29447842,  0.18742067, -0.58753335,\n","          0.6187343 ,  0.03235346,  0.0224219 ,  0.52709955,  0.30944228],\n","        [-0.14961857,  0.09334272,  0.41361946,  0.00412619, -0.60524535,\n","         -0.5115882 ,  0.2050752 , -0.14052328,  0.02605891, -0.6003347 ]],\n","       dtype=float32)>,\n"," <tf.Variable 'dense_7/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"]},"metadata":{},"execution_count":14}],"source":["# Layers have many useful methods. For example, you can inspect all variables\n","# in a layer using `layer.variables` and trainable variables using\n","# `layer.trainable_variables`. In this case a fully-connected layer\n","# will have variables for weights and biases.\n","layer.variables"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"6ilvKjz8_4MQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705887642088,"user_tz":480,"elapsed":155,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"ff83ea9d-ebb0-4040-9048-02b95553c46a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Variable 'dense_7/kernel:0' shape=(5, 10) dtype=float32, numpy=\n"," array([[ 0.41905028, -0.14225042, -0.54180515, -0.15413108,  0.56353897,\n","          0.00223833, -0.09507346, -0.296003  , -0.01942104, -0.34390724],\n","        [ 0.5273344 ,  0.34390193, -0.28642127, -0.5911583 , -0.16138011,\n","          0.22381091, -0.31642318,  0.03402799, -0.37771913, -0.3501223 ],\n","        [-0.43251273,  0.45806664,  0.38762993, -0.18399638,  0.13132632,\n","          0.41890818,  0.57048696,  0.14705741, -0.3811912 ,  0.37444776],\n","        [-0.09519547,  0.17809075,  0.29447842,  0.18742067, -0.58753335,\n","          0.6187343 ,  0.03235346,  0.0224219 ,  0.52709955,  0.30944228],\n","        [-0.14961857,  0.09334272,  0.41361946,  0.00412619, -0.60524535,\n","         -0.5115882 ,  0.2050752 , -0.14052328,  0.02605891, -0.6003347 ]],\n","       dtype=float32)>,\n"," <tf.Variable 'dense_7/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"]},"metadata":{},"execution_count":15}],"source":["# The variables are also accessible through nice accessors\n","layer.kernel, layer.bias"]},{"cell_type":"markdown","metadata":{"id":"O0kDbE54-5VS"},"source":["## Implementing custom layers\n","The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n","\n","1. `__init__` , where you can do all input-independent initialization\n","2. `build`, where you know the shapes of the input tensors and can do the rest of the initialization\n","3. `call`, where you do the forward computation\n","\n","Note that you don't have to wait until `build` is called to create your variables, you can also create them in `__init__`. However, the advantage of creating them in `build` is that it enables late variable creation based on the shape of the inputs the layer will operate on. On the other hand, creating variables in `__init__` would mean that shapes required to create the variables will need to be explicitly specified."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Byl3n1k5kIy"},"outputs":[],"source":["class MyDenseLayer(tf.keras.layers.Layer):\n","  def __init__(self, num_outputs):\n","    super(MyDenseLayer, self).__init__()\n","    self.num_outputs = num_outputs\n","\n","  def build(self, input_shape):\n","    self.kernel = self.add_weight(\"kernel\",\n","                                  shape=[int(input_shape[-1]),\n","                                         self.num_outputs])\n","\n","  def call(self, inputs):\n","    return tf.matmul(inputs, self.kernel)\n","\n","layer = MyDenseLayer(10)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"vrmBsYGOnuGO","executionInfo":{"status":"ok","timestamp":1705888309403,"user_tz":480,"elapsed":194,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}}},"outputs":[],"source":["_ = layer(tf.zeros([10, 5])) # Calling the layer `.builds` it."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"1bsLjiPfnvat","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705888314568,"user_tz":480,"elapsed":161,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"86694a3e-b57d-406f-8f44-af8d145397b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['dense_7/kernel:0', 'dense_7/bias:0']\n"]}],"source":["print([var.name for var in layer.trainable_variables])"]},{"cell_type":"markdown","metadata":{"id":"Qhg4KlbKrs3G"},"source":["## Models: Composing layers\n","\n","Many interesting layer-like things in machine learning models are implemented by composing existing layers. For example, each residual block in a resnet is a composition of convolutions, batch normalizations, and a shortcut. Layers can be nested inside other layers.\n","\n","Typically you inherit from `keras.Model` when you need the model methods like: `Model.fit`,`Model.evaluate`, and `Model.save` (see [Custom Keras layers and models](https://www.tensorflow.org/guide/keras/custom_layers_and_models) for details).\n","\n","One other feature provided by `keras.Model` (instead of `keras.layers.Layer`) is that in addition to tracking variables, a `keras.Model` also tracks its internal layers, making them easier to inspect.\n","\n","For example here is a ResNet block:"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"N30DTXiRASlb","executionInfo":{"status":"ok","timestamp":1705889140694,"user_tz":480,"elapsed":168,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}}},"outputs":[],"source":["class ResnetIdentityBlock(tf.keras.Model):\n","  def __init__(self, kernel_size, filters):\n","    super(ResnetIdentityBlock, self).__init__(name='')\n","    filters1, filters2, filters3 = filters\n","\n","    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n","    self.bn2a = tf.keras.layers.BatchNormalization()\n","\n","    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n","    self.bn2b = tf.keras.layers.BatchNormalization()\n","\n","    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n","    self.bn2c = tf.keras.layers.BatchNormalization()\n","\n","  def call(self, input_tensor, training=False):\n","    x = self.conv2a(input_tensor)\n","    x = self.bn2a(x, training=training)\n","    x = tf.nn.relu(x)\n","\n","    x = self.conv2b(x)\n","    x = self.bn2b(x, training=training)\n","    x = tf.nn.relu(x)\n","\n","    x = self.conv2c(x)\n","    x = self.bn2c(x, training=training)\n","\n","    x += input_tensor\n","    return tf.nn.relu(x)\n","\n","\n","block = ResnetIdentityBlock(1, [1, 2, 3])"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"7D8ZR5mqtokj","executionInfo":{"status":"ok","timestamp":1705889146471,"user_tz":480,"elapsed":165,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}}},"outputs":[],"source":["_ = block(tf.zeros([1, 2, 3, 3]))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MJ8rzFpdoE_m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705889144567,"user_tz":480,"elapsed":155,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"c6e41d5e-783d-42a0-de73-89ebecaa2aed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<keras.src.layers.convolutional.conv2d.Conv2D at 0x7d364b045600>,\n"," <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d35ba2f32b0>,\n"," <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d35bda0f6a0>,\n"," <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d35bda0f790>,\n"," <keras.src.layers.convolutional.conv2d.Conv2D at 0x7d35ba2f2200>,\n"," <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7d35ba2f1cf0>]"]},"metadata":{},"execution_count":20}],"source":["block.layers"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"dewldLuDvQRM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705889159354,"user_tz":480,"elapsed":373,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"0be64a5f-5059-42db-9a26-154241240954"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["18"]},"metadata":{},"execution_count":22}],"source":["len(block.variables)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"FrqIXeSetaYi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705889162918,"user_tz":480,"elapsed":842,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"73c5d739-09c0-4694-ce68-afd2fcf3e95a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             multiple                  4         \n","                                                                 \n"," batch_normalization (Batch  multiple                  4         \n"," Normalization)                                                  \n","                                                                 \n"," conv2d_1 (Conv2D)           multiple                  4         \n","                                                                 \n"," batch_normalization_1 (Bat  multiple                  8         \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_2 (Conv2D)           multiple                  9         \n","                                                                 \n"," batch_normalization_2 (Bat  multiple                  12        \n"," chNormalization)                                                \n","                                                                 \n","=================================================================\n","Total params: 41 (164.00 Byte)\n","Trainable params: 29 (116.00 Byte)\n","Non-trainable params: 12 (48.00 Byte)\n","_________________________________________________________________\n"]}],"source":["block.summary()"]},{"cell_type":"markdown","metadata":{"id":"wYfucVw65PMj"},"source":["Much of the time, however, models which compose many layers simply call one layer after the other. This can be done in very little code using `tf.keras.Sequential`:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"L9frk7Ur4uvJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705889221995,"user_tz":480,"elapsed":147,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"e1d62645-3d6d-4b4e-cafd-2c748d1f715c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n","array([[[[0., 0., 0.],\n","         [0., 0., 0.],\n","         [0., 0., 0.]],\n","\n","        [[0., 0., 0.],\n","         [0., 0., 0.],\n","         [0., 0., 0.]]]], dtype=float32)>"]},"metadata":{},"execution_count":24}],"source":["my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n","                                                    input_shape=(\n","                                                        None, None, 3)),\n","                             tf.keras.layers.BatchNormalization(),\n","                             tf.keras.layers.Conv2D(2, 1,\n","                                                    padding='same'),\n","                             tf.keras.layers.BatchNormalization(),\n","                             tf.keras.layers.Conv2D(3, (1, 1)),\n","                             tf.keras.layers.BatchNormalization()])\n","my_seq(tf.zeros([1, 2, 3, 3]))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"tVAsbFITuScB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705889225215,"user_tz":480,"elapsed":149,"user":{"displayName":"Ashkan Bozorgzad","userId":"17492030002853620211"}},"outputId":"7807d2be-1d26-4f35-dfd2-51a79416fcda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, None, None, 1)     4         \n","                                                                 \n"," batch_normalization_3 (Bat  (None, None, None, 1)     4         \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, None, None, 2)     4         \n","                                                                 \n"," batch_normalization_4 (Bat  (None, None, None, 2)     8         \n"," chNormalization)                                                \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, None, None, 3)     9         \n","                                                                 \n"," batch_normalization_5 (Bat  (None, None, None, 3)     12        \n"," chNormalization)                                                \n","                                                                 \n","=================================================================\n","Total params: 41 (164.00 Byte)\n","Trainable params: 29 (116.00 Byte)\n","Non-trainable params: 12 (48.00 Byte)\n","_________________________________________________________________\n"]}],"source":["my_seq.summary()"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/customization/custom_layers.ipynb","timestamp":1705877381599}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}